{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "\n",
    "from random import choice, randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting all the attributes from each product page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this case we do not need selenium, as a simple request suffices\n",
    "- We will only store the relevant attributes as json in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output'\n",
    "output_folder = output_path\n",
    "\n",
    "# Load json file from ikea_products.json which we will use as refference to know which pages to hit\n",
    "with open(os.path.join(output_path, 'ikea_products.json'), encoding=\"utf-8\") as f:\n",
    "    target_products = json.load(f)\n",
    "\n",
    "# Check if there is a file named full_product_extraction.json if not create it\n",
    "# We will use this file to keep track of the categories we have already extracted\n",
    "output_fname = os.path.join(output_path, 'full_product_extraction.json')\n",
    "if not os.path.isfile(output_fname):\n",
    "    with open(output_fname, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump([], f)\n",
    "        extracted_products = []\n",
    "else:\n",
    "    with open(output_fname, encoding=\"utf-8\") as f:\n",
    "        extracted_products = json.load(f)\n",
    "\n",
    "previously_extracted_urls_fname = os.path.join(output_path, 'extracted_product_urls.json')\n",
    "if not os.path.isfile(previously_extracted_urls_fname):\n",
    "    with open(previously_extracted_urls_fname, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump([], f)\n",
    "        previously_extracted_urls = []\n",
    "else:\n",
    "    with open(previously_extracted_urls_fname, encoding=\"utf-8\") as f:\n",
    "        previously_extracted_urls = json.load(f)\n",
    "\n",
    "# Do the same for call_record.json\n",
    "if not os.path.isfile(os.path.join(output_path, 'request_records.json')):\n",
    "    with open(os.path.join(output_path, 'request_records.json'), 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump([], f)\n",
    "        call_record = []\n",
    "else:\n",
    "    with open(os.path.join(output_path, 'request_records.json'), encoding=\"utf-8\") as f:\n",
    "        call_record = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def write_json_file(file_path, data):\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def append_to_json_list(file_path, new_elements):\n",
    "    # Read the existing data\n",
    "    data = read_json_file(file_path)\n",
    "    \n",
    "    # Check if the data is a list\n",
    "    if isinstance(data, list):\n",
    "        # Append new elements to the list\n",
    "        data.extend(new_elements)\n",
    "    else:\n",
    "        raise ValueError(\"JSON data is not a list\")\n",
    "    \n",
    "    # Write the updated list back to the file\n",
    "    write_json_file(file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store log entries\n",
    "log_entries = []\n",
    "unsuccessful_request_count = 0\n",
    "\n",
    "def log_action(action, result, elapsed_time=None):\n",
    "    global log_entries, unsuccessful_request_count  # Declare the global variables\n",
    "    \n",
    "    log_entry = {\n",
    "        \"timestamp\": time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"action\": action,\n",
    "        \"result\": result,\n",
    "        \"time_taken\": f\"{elapsed_time:.2f}\" if elapsed_time is not None else \"N/A\"\n",
    "    }\n",
    "    log_entries.append(log_entry)  # Append the log entry to the global list\n",
    "\n",
    "    # Update the unsuccessful request count\n",
    "    if result.lower() != \"success\":\n",
    "        unsuccessful_request_count += 1\n",
    "    else:\n",
    "        unsuccessful_request_count = 0\n",
    "    \n",
    "    return log_entry\n",
    "\n",
    "def get_unsuccessful_request_count():\n",
    "    global unsuccessful_request_count  # Declare the global variable\n",
    "    return unsuccessful_request_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_attributes(product, cookie, headers):\n",
    "    \"\"\"\n",
    "    Extract product attributes from the product page and return the results as a dictionary\n",
    "    Only extract one single attribute per function call\n",
    "    Inputs:\n",
    "        product_url: Dictionary of the product with keys url, name and category\n",
    "        cookie: Cookie to be used in the request, should have been previously obtained. It is a good idea to use the same cookie for all requests with same headers\n",
    "        headers: Headers to be used in the request\n",
    "    Outputs:\n",
    "        product_attributes: Dictionary containing the extracted product attributes\n",
    "    \"\"\"\n",
    "\n",
    "    action = \"Request to individual product page\"\n",
    "    url = product[\"url\"]\n",
    "    # Make the GET request\n",
    "    # We may need to remove headers, or iterate using different profiles\n",
    "    start_time = time.time()\n",
    "    response = requests.get(url, headers=headers, cookies=cookie)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    # Check the response\n",
    "    if response.status_code == 200:\n",
    "        log_action(action, \"Success\", elapsed_time)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # extracting JSON object from a script tag within the HTML\n",
    "        product_div = soup.find('div', class_='pip-product__subgrid product-pip js-product-pip')\n",
    "        if product_div:\n",
    "            # Extract the 'data-hydration-props' attribute, which contains JSON\n",
    "            json_data_attr = product_div['data-hydration-props']\n",
    "            \n",
    "            # Convert HTML entities and escaped quotes to normal form\n",
    "            json_data_attr = json_data_attr.replace('&quot;', '\"')\n",
    "            \n",
    "            # Load string into a JSON object\n",
    "            data = json.loads(json_data_attr)\n",
    "\n",
    "            price_dict = data[\"pipPriceModule\"][\"price\"][\"mainPriceProps\"][\"price\"]\n",
    "            product_price = f\"{price_dict['integer']}.{price_dict['decimals']}\"\n",
    "            # Convert price to float\n",
    "            product_price = float(product_price)\n",
    "            currency = data[\"pipPriceModule\"][\"price\"][\"mainPriceProps\"][\"currencySymbol\"]\n",
    "            # We get product dimensions for the full product\n",
    "            product_measurement_text = data[\"pipPriceModule\"][\"measurementText\"]\n",
    "\n",
    "            product_dimensions_json = data[\"productInformationSection\"][\"dimensionProps\"][\"packaging\"][\"contentProps\"]\n",
    "\n",
    "            product_dictionary = product_dimensions_json\n",
    "            product_dictionary[\"price\"] = product_price\n",
    "            product_dictionary[\"currency\"] = currency\n",
    "            product_dictionary[\"measurement_ensembled_text\"] = product_measurement_text\n",
    "            product_dictionary[\"url\"] = url\n",
    "            product_dictionary[\"name\"] = product[\"name\"]\n",
    "            product_dictionary[\"category\"] = product[\"category\"]\n",
    "            \n",
    "            return product_dictionary\n",
    "            \n",
    "    else:\n",
    "        log_action(action, \"Failed\", elapsed_time)\n",
    "        print(\"Failed to retrieve the page, status code:\", response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = [\n",
    "    {\n",
    "        'guest': 'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImVxSFFLR3duR3hfV3dJZkx0RGpaeDA5MTUzS2xSam5fVE1nVUlMYlJ5RncifQ.eyJpc3MiOiJodHRwczovL2FwaS5pbmdrYS5pa2VhLmNvbS9ndWVzdCIsInN1YiI6ImIwMDJmYTBkLTkwMjEtNGQ2My04YzlkLTJhZDNlZjM0ZjE0YiIsInJldGFpbFVuaXQiOiJlcyIsImlhdCI6MTcxNTQ1MTY0MCwiZXhwIjoxNzE4MDQzNjQwfQ.NS0sPhnYbArE-750pTzE4_5I6wsCRgZxlKa0Cfyf0Z4bKi5jsfvcFWRS88jz6d0O1z6wLmfN5XN0tseCMzouaeLW_jmxGQ5qQF1_9J9uJny7R3t37Ku_lT41Psbu1ymQra2cLOZWwbungu41bNClWd3p3k4NaOXWx2fcivZrFUo'\n",
    "    }\n",
    "]\n",
    "headers = [\n",
    "    {\n",
    "        'Host': 'www.ikea.com',\n",
    "        'Sec-Ch-Ua': '\"Not-A.Brand\";v=\"99\", \"Chromium\";v=\"124\"',\n",
    "        'Sec-Ch-Ua-Mobile': '?0',\n",
    "        'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.6367.118 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Sec-Fetch-Site': 'none',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Sec-Fetch-Dest': 'document',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'es-ES,es;q=0.9',\n",
    "        'Connection': 'close'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_products = [product for product in target_products if product[\"url\"] not in previously_extracted_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted product 1 out of 8103\n",
      "extracted product 2 out of 8103\n",
      "extracted product 3 out of 8103\n",
      "extracted product 4 out of 8103\n",
      "extracted product 5 out of 8103\n"
     ]
    }
   ],
   "source": [
    "full_product_extraction = []\n",
    " \n",
    "for idx, target_product in enumerate(target_products):\n",
    "    sleep_time = randint(1, 3)\n",
    "    if (idx+1) % 10 == 0:\n",
    "        cookie = choice(cookies)\n",
    "        header = choice(headers)\n",
    "        append_to_json_list(output_fname, full_product_extraction)\n",
    "        full_product_extraction = []\n",
    "        append_to_json_list(os.path.join(output_path, 'request_records.json'), log_entries)\n",
    "        log_entries = []\n",
    "\n",
    "    product = target_product\n",
    "    product_attributes = extract_product_attributes(product, cookie, header)\n",
    "    print(f\"extracted product {idx+1} out of {len(target_products)}\")\n",
    "\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    full_product_extraction.append(product_attributes)\n",
    "    previously_extracted_urls.append(target_product[\"url\"])\n",
    "\n",
    "    if unsuccessful_request_count > 4:\n",
    "        break\n",
    "\n",
    "append_to_json_list(output_fname, full_product_extraction)\n",
    "append_to_json_list(os.path.join(output_path, 'request_records.json'), log_entries)\n",
    "write_json_file(previously_extracted_urls_fname, previously_extracted_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
