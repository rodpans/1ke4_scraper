{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "\n",
    "from random import choice, randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting all the attributes from each product page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this case we do not need selenium, as a simple request suffices\n",
    "- We will only store the relevant attributes as json in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output'\n",
    "output_folder = output_path\n",
    "\n",
    "# Load json file from ikea_products.json which we will use as refference to know which pages to hit\n",
    "with open(os.path.join(output_path, 'ikea_products.json'), encoding=\"utf-8\") as f:\n",
    "    target_products = json.load(f)\n",
    "\n",
    "# Check if there is a file named full_product_extraction.json if not create it\n",
    "# We will use this file to keep track of the categories we have already extracted\n",
    "output_fname = os.path.join(output_path, 'full_product_extraction.json')\n",
    "if not os.path.isfile(output_fname):\n",
    "    with open(output_fname, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump([], f)\n",
    "        extracted_products = []\n",
    "else:\n",
    "    with open(output_fname, encoding=\"utf-8\") as f:\n",
    "        extracted_products = json.load(f)\n",
    "\n",
    "previously_extracted_urls_fname = os.path.join(output_path, 'extracted_product_urls.json')\n",
    "if not os.path.isfile(previously_extracted_urls_fname):\n",
    "    with open(previously_extracted_urls_fname, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump([], f)\n",
    "        previously_extracted_urls = []\n",
    "else:\n",
    "    with open(previously_extracted_urls_fname, encoding=\"utf-8\") as f:\n",
    "        previously_extracted_urls = json.load(f)\n",
    "\n",
    "# Do the same for call_record.json\n",
    "if not os.path.isfile(os.path.join(output_path, 'request_records.json')):\n",
    "    with open(os.path.join(output_path, 'request_records.json'), 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump([], f)\n",
    "        call_record = []\n",
    "else:\n",
    "    with open(os.path.join(output_path, 'request_records.json'), encoding=\"utf-8\") as f:\n",
    "        call_record = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def write_json_file(file_path, data):\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def append_to_json_list(file_path, new_elements):\n",
    "    # Read the existing data\n",
    "    data = read_json_file(file_path)\n",
    "    \n",
    "    # Check if the data is a list\n",
    "    if isinstance(data, list):\n",
    "        # Append new elements to the list\n",
    "        data.extend(new_elements)\n",
    "    else:\n",
    "        raise ValueError(\"JSON data is not a list\")\n",
    "    \n",
    "    # Write the updated list back to the file\n",
    "    write_json_file(file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store log entries\n",
    "log_entries = []\n",
    "unsuccessful_request_count = 0\n",
    "\n",
    "def log_action(action, result, elapsed_time=None):\n",
    "    global log_entries, unsuccessful_request_count  # Declare the global variables\n",
    "    \n",
    "    log_entry = {\n",
    "        \"timestamp\": time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"action\": action,\n",
    "        \"result\": result,\n",
    "        \"time_taken\": f\"{elapsed_time:.2f}\" if elapsed_time is not None else \"N/A\"\n",
    "    }\n",
    "    log_entries.append(log_entry)  # Append the log entry to the global list\n",
    "\n",
    "    # Update the unsuccessful request count\n",
    "    if result.lower() != \"success\":\n",
    "        unsuccessful_request_count += 1\n",
    "    else:\n",
    "        unsuccessful_request_count = 0\n",
    "    \n",
    "    return log_entry\n",
    "\n",
    "def get_unsuccessful_request_count():\n",
    "    global unsuccessful_request_count  # Declare the global variable\n",
    "    return unsuccessful_request_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_attributes(product, cookie, headers):\n",
    "    \"\"\"\n",
    "    Extract product attributes from the product page and return the results as a dictionary\n",
    "    Only extract one single attribute per function call\n",
    "    Inputs:\n",
    "        product_url: Dictionary of the product with keys url, name and category\n",
    "        cookie: Cookie to be used in the request, should have been previously obtained. It is a good idea to use the same cookie for all requests with same headers\n",
    "        headers: Headers to be used in the request\n",
    "    Outputs:\n",
    "        product_attributes: Dictionary containing the extracted product attributes\n",
    "    \"\"\"\n",
    "\n",
    "    action = \"Request to individual product page\"\n",
    "    url = product[\"url\"]\n",
    "    # Make the GET request\n",
    "    # We may need to remove headers, or iterate using different profiles\n",
    "    start_time = time.time()\n",
    "    response = requests.get(url, headers=headers, cookies=cookie)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    # Check the response\n",
    "    if response.status_code == 200:\n",
    "        log_action(action, \"Success\", elapsed_time)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # extracting JSON object from a script tag within the HTML\n",
    "        product_div = soup.find('div', class_='pip-product__subgrid product-pip js-product-pip')\n",
    "        if product_div:\n",
    "            # Extract the 'data-hydration-props' attribute, which contains JSON\n",
    "            json_data_attr = product_div['data-hydration-props']\n",
    "            \n",
    "            # Convert HTML entities and escaped quotes to normal form\n",
    "            json_data_attr = json_data_attr.replace('&quot;', '\"')\n",
    "            \n",
    "            # Load string into a JSON object\n",
    "            data = json.loads(json_data_attr)\n",
    "\n",
    "            price_dict = data[\"pipPriceModule\"][\"price\"][\"mainPriceProps\"][\"price\"]\n",
    "            integer_price = price_dict[\"integer\"].replace(\".\", \"\")\n",
    "            product_price = f\"{integer_price}.{price_dict['decimals']}\"\n",
    "            # Convert price to float\n",
    "            product_price = float(product_price)\n",
    "            currency = data[\"pipPriceModule\"][\"price\"][\"mainPriceProps\"][\"currencySymbol\"]\n",
    "            # We get product dimensions for the full product\n",
    "            product_measurement_text = data[\"pipPriceModule\"][\"measurementText\"]\n",
    "\n",
    "            product_dimensions_json = data[\"productInformationSection\"][\"dimensionProps\"][\"packaging\"][\"contentProps\"]\n",
    "\n",
    "            product_dictionary = product_dimensions_json\n",
    "            product_dictionary[\"price\"] = product_price\n",
    "            product_dictionary[\"currency\"] = currency\n",
    "            product_dictionary[\"measurement_ensembled_text\"] = product_measurement_text\n",
    "            product_dictionary[\"url\"] = url\n",
    "            product_dictionary[\"name\"] = product[\"name\"]\n",
    "            product_dictionary[\"category\"] = product[\"category\"]\n",
    "            \n",
    "            return product_dictionary\n",
    "            \n",
    "    else:\n",
    "        log_action(action, \"Failed\", elapsed_time)\n",
    "        print(\"Failed to retrieve the page, status code:\", response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = [\n",
    "    {\n",
    "        'guest': 'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImVxSFFLR3duR3hfV3dJZkx0RGpaeDA5MTUzS2xSam5fVE1nVUlMYlJ5RncifQ.eyJpc3MiOiJodHRwczovL2FwaS5pbmdrYS5pa2VhLmNvbS9ndWVzdCIsInN1YiI6ImIwMDJmYTBkLTkwMjEtNGQ2My04YzlkLTJhZDNlZjM0ZjE0YiIsInJldGFpbFVuaXQiOiJlcyIsImlhdCI6MTcxNTQ1MTY0MCwiZXhwIjoxNzE4MDQzNjQwfQ.NS0sPhnYbArE-750pTzE4_5I6wsCRgZxlKa0Cfyf0Z4bKi5jsfvcFWRS88jz6d0O1z6wLmfN5XN0tseCMzouaeLW_jmxGQ5qQF1_9J9uJny7R3t37Ku_lT41Psbu1ymQra2cLOZWwbungu41bNClWd3p3k4NaOXWx2fcivZrFUo'\n",
    "    }\n",
    "]\n",
    "headers = [\n",
    "    {\n",
    "        'Host': 'www.ikea.com',\n",
    "        'Sec-Ch-Ua': '\"Not-A.Brand\";v=\"99\", \"Chromium\";v=\"124\"',\n",
    "        'Sec-Ch-Ua-Mobile': '?0',\n",
    "        'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.6367.118 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Sec-Fetch-Site': 'none',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Sec-Fetch-Dest': 'document',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'es-ES,es;q=0.9',\n",
    "        'Connection': 'close'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_products = [product for product in target_products if product[\"url\"] not in previously_extracted_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_attributes = extract_product_attributes(product, cookie, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted product 1 out of 8103\n",
      "extracted product 2 out of 8103\n",
      "extracted product 3 out of 8103\n",
      "extracted product 4 out of 8103\n",
      "extracted product 5 out of 8103\n",
      "extracted product 6 out of 8103\n",
      "extracted product 7 out of 8103\n",
      "extracted product 8 out of 8103\n",
      "extracted product 9 out of 8103\n",
      "extracted product 10 out of 8103\n",
      "extracted product 11 out of 8103\n",
      "extracted product 12 out of 8103\n",
      "extracted product 13 out of 8103\n",
      "extracted product 14 out of 8103\n",
      "extracted product 15 out of 8103\n",
      "extracted product 16 out of 8103\n",
      "extracted product 17 out of 8103\n",
      "extracted product 18 out of 8103\n",
      "extracted product 19 out of 8103\n",
      "extracted product 20 out of 8103\n",
      "extracted product 21 out of 8103\n",
      "extracted product 22 out of 8103\n",
      "extracted product 23 out of 8103\n",
      "extracted product 24 out of 8103\n",
      "extracted product 25 out of 8103\n",
      "extracted product 26 out of 8103\n",
      "extracted product 27 out of 8103\n",
      "extracted product 28 out of 8103\n",
      "extracted product 29 out of 8103\n",
      "extracted product 30 out of 8103\n",
      "extracted product 31 out of 8103\n",
      "extracted product 32 out of 8103\n",
      "extracted product 33 out of 8103\n",
      "extracted product 34 out of 8103\n",
      "extracted product 35 out of 8103\n",
      "extracted product 36 out of 8103\n",
      "extracted product 37 out of 8103\n",
      "extracted product 38 out of 8103\n",
      "extracted product 39 out of 8103\n",
      "extracted product 40 out of 8103\n",
      "extracted product 41 out of 8103\n",
      "extracted product 42 out of 8103\n",
      "extracted product 43 out of 8103\n",
      "extracted product 44 out of 8103\n",
      "extracted product 45 out of 8103\n",
      "extracted product 46 out of 8103\n",
      "extracted product 47 out of 8103\n",
      "extracted product 48 out of 8103\n",
      "extracted product 49 out of 8103\n",
      "extracted product 50 out of 8103\n",
      "extracted product 51 out of 8103\n",
      "extracted product 52 out of 8103\n",
      "extracted product 53 out of 8103\n",
      "extracted product 54 out of 8103\n",
      "extracted product 55 out of 8103\n",
      "extracted product 56 out of 8103\n",
      "extracted product 57 out of 8103\n",
      "extracted product 58 out of 8103\n",
      "extracted product 59 out of 8103\n",
      "extracted product 60 out of 8103\n",
      "extracted product 61 out of 8103\n",
      "extracted product 62 out of 8103\n",
      "extracted product 63 out of 8103\n",
      "extracted product 64 out of 8103\n",
      "extracted product 65 out of 8103\n",
      "extracted product 66 out of 8103\n",
      "extracted product 67 out of 8103\n",
      "extracted product 68 out of 8103\n",
      "extracted product 69 out of 8103\n",
      "extracted product 70 out of 8103\n",
      "extracted product 71 out of 8103\n",
      "extracted product 72 out of 8103\n",
      "extracted product 73 out of 8103\n",
      "extracted product 74 out of 8103\n",
      "extracted product 75 out of 8103\n",
      "extracted product 76 out of 8103\n",
      "extracted product 77 out of 8103\n",
      "extracted product 78 out of 8103\n",
      "extracted product 79 out of 8103\n",
      "extracted product 80 out of 8103\n",
      "extracted product 81 out of 8103\n",
      "extracted product 82 out of 8103\n",
      "extracted product 83 out of 8103\n",
      "extracted product 84 out of 8103\n",
      "extracted product 85 out of 8103\n",
      "extracted product 86 out of 8103\n",
      "extracted product 87 out of 8103\n",
      "extracted product 88 out of 8103\n",
      "extracted product 89 out of 8103\n",
      "extracted product 90 out of 8103\n",
      "extracted product 91 out of 8103\n",
      "extracted product 92 out of 8103\n",
      "extracted product 93 out of 8103\n",
      "extracted product 94 out of 8103\n",
      "extracted product 95 out of 8103\n",
      "extracted product 96 out of 8103\n",
      "extracted product 97 out of 8103\n",
      "extracted product 98 out of 8103\n",
      "extracted product 99 out of 8103\n",
      "extracted product 100 out of 8103\n",
      "extracted product 101 out of 8103\n",
      "extracted product 102 out of 8103\n",
      "extracted product 103 out of 8103\n",
      "extracted product 104 out of 8103\n",
      "extracted product 105 out of 8103\n",
      "extracted product 106 out of 8103\n",
      "extracted product 107 out of 8103\n",
      "extracted product 108 out of 8103\n",
      "extracted product 109 out of 8103\n",
      "extracted product 110 out of 8103\n",
      "extracted product 111 out of 8103\n",
      "extracted product 112 out of 8103\n",
      "extracted product 113 out of 8103\n",
      "extracted product 114 out of 8103\n",
      "extracted product 115 out of 8103\n",
      "extracted product 116 out of 8103\n",
      "extracted product 117 out of 8103\n",
      "extracted product 118 out of 8103\n",
      "extracted product 119 out of 8103\n",
      "extracted product 120 out of 8103\n",
      "extracted product 121 out of 8103\n",
      "extracted product 122 out of 8103\n",
      "extracted product 123 out of 8103\n",
      "extracted product 124 out of 8103\n",
      "extracted product 125 out of 8103\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1.045.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     log_entries \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m product \u001b[38;5;241m=\u001b[39m target_product\n\u001b[1;32m---> 14\u001b[0m product_attributes \u001b[38;5;241m=\u001b[39m \u001b[43mextract_product_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcookie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracted product \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(target_products)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(sleep_time)\n",
      "Cell \u001b[1;32mIn[18], line 42\u001b[0m, in \u001b[0;36mextract_product_attributes\u001b[1;34m(product, cookie, headers)\u001b[0m\n\u001b[0;32m     40\u001b[0m product_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecimals\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Convert price to float\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m product_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproduct_price\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m currency \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipPriceModule\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmainPriceProps\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrencySymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# We get product dimensions for the full product\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '1.045.'"
     ]
    }
   ],
   "source": [
    "full_product_extraction = []\n",
    "max_n_profile_uses = 100\n",
    "for idx, target_product in enumerate(target_products):\n",
    "    sleep_time = randint(1, 3)\n",
    "    if (idx+1) % max_n_profile_uses == 0:\n",
    "        cookie = choice(cookies)\n",
    "        header = choice(headers)\n",
    "        append_to_json_list(output_fname, full_product_extraction)\n",
    "        full_product_extraction = []\n",
    "        append_to_json_list(os.path.join(output_path, 'request_records.json'), log_entries)\n",
    "        log_entries = []\n",
    "\n",
    "    product = target_product\n",
    "    product_attributes = extract_product_attributes(product, cookie, header)\n",
    "    print(f\"extracted product {idx+1} out of {len(target_products)}\")\n",
    "\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    full_product_extraction.append(product_attributes)\n",
    "    previously_extracted_urls.append(target_product[\"url\"])\n",
    "\n",
    "    if unsuccessful_request_count > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_json_list(output_fname, full_product_extraction)\n",
    "append_to_json_list(os.path.join(output_path, 'request_records.json'), log_entries)\n",
    "write_json_file(previously_extracted_urls_fname, previously_extracted_urls)\n",
    "full_product_extraction = []\n",
    "log_entries = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
